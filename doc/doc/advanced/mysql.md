---
layout: default
---

# Using DeepDive with MySQL / MySQL Cluster

This document describes how to use DeepDive with
[MySQL](http://www.mysql.com/) and 
[MySQL Cluster](http://www.mysql.com/products/cluster/).

We still encourage developers to use PostgreSQL or
[GreenPlum](greenplum.html) since it gives maximum functionality of
DeepDive. However, DeepDive should also work well with MySQL or MySQL
cluster, other than caveats below.

### Common Caveats

Extractor types: only [tsv_extractor](../basics/extractors.html#tsv_extractor), 
[sql_extractor](../basics/extractors.html#sql_extractor) 
and [cmd_extractor](../basics/extractors.html#cmd_extractor) are supported.

When loading data into MySQL server, DeepDive by default uses `LOAD DATA INFILE`.
If you want loading data from the client (`LOAD DATA LOCAL INFILE`), 
specify an environment variable `MYSQL_LOCAL_INFILE=1`.

When using TSV extractor, make sure you are aware of the following caveats:

- `NULL` columns in extractor input
  are string `NULL`, which has different behavior with Postgres (input
  to extractor is `\N`). If you want to output NULL values in extractors
  in MySQL, you still need to output `\N`.

- Boolean fields in extractor input are `0` or `1`, which has different 
  behavior with Postgres (input
  to extractor is `true` / `false`). If you want to output boolean values in extractors
  in MySQL, you also need to output `0` / `1`.

If you are porting your applications from PostgreSQL to MySQL, be sure
your SQL queries are optimal, since some queries optimized for
PostgreSQL may be not optimal in MySQL. For example, you may need to
create more indexes to speed up queries with joins, depending on your
MySQL version.

### Caveats for MySQL Cluster

<!-- If you are using MySQL cluster, you may want to use the 
[parallel data loader](#ndbloader) discussed below, to speed up the data 
loading process.
 -->

For MySQL cluster, tables need to be partitioned since "Partitioning by KEY (including LINEAR KEY) is the only type of partitioning supported for the NDB storage engine". (http://dev.mysql.com/doc/refman/5.6/en/partitioning-limitations-storage-engines.html)

You need to distribute tables by a key which are not text/blob.

<!-- ### Parallel data loader for MySQL Cluster

Data loading for MySQL Cluster can be slow using SQL interfaces. MySQL Cluster has provided [NDB API](http://dev.mysql.com/doc/ndbapi/en/) for faster access to cluster data. We provide a data loader in `DEEPDIVE_HOME/util/ndbloader` that can be used to load data files in TSV format into MySQL cluster.

We integrate this parallel loader into data loading in our [extractors](../basics/extractors.html). 
With a tag `parallel_load: true` in any extractor in `application.conf`, data generated by extractors will be loaded into database using `ndbloader`. 

Currently our `ndbloader` can only load data in TSV format, without line breaks or `\t` characters in data. It can only load data into tables with following column types:

- INT/BIGINT, or equivalent types
- FLOAT/DOUBLE, or equivalent types
- TEXT
- VARCHAR
- CHAR

TODO schema file format

TODO writing in application.conf -->


### Best practices

When configuring your MySQL cluster, be sure to follow available best practices online such as [this page](https://blogs.oracle.com/MySQL/entry/mysql_cluster_performance_best_practices). 

## <a name="faq" href="#"></a> FAQs

- **When using the data loader with MySQL Cluster, I got errors 
"Time-out in NDB, probably caused by deadlock".**

  Consider turning the `TransactionDeadlockDetectionTimeout` into a larger value (e.g. 60000) in your MySQL Cluster configuration.

- **In grounding phase, I got "ERROR 1297 (HY000): Got temporary error 
233 ': Out of operation records in transaction coordinator (increase 
MaxNoOfConcurrentOperations)"**

  Try to increase `MaxNoOfConcurrentOperations` and `MaxNoOfConcurrentTransactions` in your MySQL Cluster configuration.

