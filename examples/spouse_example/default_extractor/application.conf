deepdive {
  
  db.default {
    driver: "org.postgresql.Driver"
    url: "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME} #"
    user: ${PGUSER}
    password: ${PGPASSWORD}
  }

  # Put your variables here
  schema.variables {
    has_spouse.is_true: Boolean
  }

  # Put your extractors here
  extraction.extractors {

    # nlp_extractor only supports the default extractor.
    ext_sentences: {
      input: "SELECT article_id, text FROM articles order by article_id asc"
      output_relation: "sentences"
      udf: ${DEEPDIVE_HOME}"/examples/nlp_extractor/run.sh -k article_id -v text -l 20 -t 4"
      before: ${APP_HOME}"/../script/before_sentences.sh"
      after: ${APP_HOME}"/../script/fill_sequence.sh sentences sentence_id"
      input_batch_size: 10
      output_batch_size: 1000
    }


    ext_people {
      input: """
          SELECT  sentence_id, words, ner_tags
          FROM    sentences
          """
      output_relation: "people_mentions"
      udf: ${APP_HOME}"/udf/ext_people.py"
      before: ${APP_HOME}"/../script/before_people.sh"
      after: ${APP_HOME}"/../script/fill_sequence.sh people_mentions mention_id"
      dependencies: ["ext_sentences"]
    }

    ext_has_spouse_candidates {
      input: """
        SELECT  sentences.sentence_id, 
                p1.mention_id AS "p1.mention_id", 
                p1.text AS "p1.text", 
                p2.mention_id AS "p2.mention_id", 
                p2.text AS "p2.text" 
         FROM   people_mentions p1, 
                people_mentions p2, 
                sentences 
        WHERE   p1.sentence_id = p2.sentence_id 
          AND   p1.sentence_id = sentences.sentence_id 
          AND   p1.mention_id != p2.mention_id;
          """
      output_relation: "has_spouse"
      udf: ${APP_HOME}"/udf/ext_has_spouse.py"
      before: ${APP_HOME}"/../script/before_has_spouse.sh"
      after: ${APP_HOME}"/../script/fill_sequence.sh has_spouse relation_id"
      dependencies: ["ext_people"]
    }

    ext_has_spouse_features {
      input: """
        SELECT  sentences.words, 
                has_spouse.relation_id, 
                p1.start_position AS "p1.start_position", 
                p1.length AS "p1.length", 
                p2.start_position AS "p2.start_position", 
                p2.length AS "p2.length"
          FROM  has_spouse, 
                people_mentions p1, 
                people_mentions p2, 
                sentences
         WHERE  has_spouse.person1_id = p1.mention_id 
           AND  has_spouse.person2_id = p2.mention_id 
           AND  has_spouse.sentence_id = sentences.sentence_id;
           """
      output_relation: "has_spouse_features"
      udf: ${APP_HOME}"/udf/ext_has_spouse_features.py"
      before: ${APP_HOME}"/../script/before_has_spouse_features.sh"
      dependencies: ["ext_has_spouse_candidates"]
    }

  }

  inference.factors: { 

    f_has_spouse_features.input_query: """
        SELECT  has_spouse.id AS "has_spouse.id", 
                has_spouse.is_true AS "has_spouse.is_true", 
                feature 
        FROM    has_spouse, 
                has_spouse_features 
        WHERE   has_spouse_features.relation_id = has_spouse.relation_id
        """
    f_has_spouse_features.function: "IsTrue(has_spouse.is_true)"
    f_has_spouse_features.weight: "?(feature)"

    f_has_spouse_symmetry.input_query: """
        SELECT  r1.is_true AS "has_spouse.r1.is_true", 
                r2.is_true AS "has_spouse.r2.is_true", 
                r1.id AS "has_spouse.r1.id", 
                r2.id AS "has_spouse.r2.id"
        FROM    has_spouse r1, 
                has_spouse r2 
        WHERE   r1.person1_id = r2.person2_id 
          AND   r1.person2_id = r2.person1_id
          """
    f_has_spouse_symmetry.function: "Imply(has_spouse.r1.is_true, has_spouse.r2.is_true)"
    f_has_spouse_symmetry.weight: "?"

  }

  # # If you want to re-extract all sentences:
  # pipeline.run: "nlp"
  # pipeline.pipelines.nlp: ["ext_sentences"]
  pipeline.run: "nonlp"
  pipeline.pipelines.nonlp: [
    "ext_people",
    "ext_has_spouse_candidates",
    "ext_has_spouse_features",
    "f_has_spouse_features", "f_has_spouse_symmetry"
    ]
  pipeline.pipelines.inference: ["f_has_spouse_features", "f_has_spouse_symmetry"]

  # Specify a holdout fraction
  calibration.holdout_fraction: 0.25

  # sampler.sampler_cmd: "util/sampler-dw-linux gibbs"
  sampler.sampler_args: "-l 1000 -s 1 -i 1000 --alpha 0.1 --diminish 0.99"

}
